# 预测结果权重分析报告

## 一、权重分配机制

### 1.1 动态权重计算流程

预测阶段的权重分配采用 **IC-IR（信息比率）动态加权**机制：

```
训练阶段 → 计算各模型在验证集上的 IC → 计算 IC-IR → 预测阶段根据 IC-IR 分配权重
```

**关键代码位置**：
- `predictor/weight_dynamic.py::RankICDynamicWeighter`：计算 IC-IR 和权重
- `predictor/predictor.py::predict()`：使用权重融合各模型预测

### 1.2 权重计算公式

```python
# 1. 计算 IC-IR（信息比率）
IC-IR = mean(IC) / std(IC)  # 使用指数衰减权重，越近的 IC 权重越大

# 2. 归一化权重
weights = {model: IC-IR / sum(IC-IR) for model in models}

# 3. 施加约束（min_weight=0.05, max_weight=0.7）
weights = clip(weights, min=0.05, max=0.7)
weights = weights / sum(weights)  # 重新归一化
```

### 1.3 实际权重分配（基于训练日志）

根据最近 20 个训练窗口的 IC 统计：

| 模型 | 平均IC | IC标准差 | IC-IR | 预期权重范围 |
|------|--------|----------|-------|--------------|
| **qlib_ensemble** | 0.1452 | 0.0858 | **1.6929** | 最高（接近 max_weight=0.7） |
| **stack** | 0.1554 | 0.1013 | **1.5343** | 较高 |
| **lgb** | 0.1585 | 0.1085 | **1.4607** | 较高 |
| **mlp** | 0.0950 | 0.0726 | **1.3097** | 较低（接近 min_weight=0.05） |

**结论**：
- **qlib_ensemble** 的 IC-IR 最高（1.69），应该获得最高权重
- **MLP** 的 IC-IR 最低（1.31），权重应该最低
- 由于有 min_weight=0.05 的约束，MLP 仍会获得至少 5% 的权重

## 二、各模型预测结果分析

### 2.1 预测值统计

**数据概览**：
- 总样本数：286,620
- 日期范围：2021-10-08 到 2025-09-30
- 股票数量：300（CSI300）

**各模型预测值统计**（经过 Rank 转换后，范围 [0, 1]）：

| 模型 | 均值 | 标准差 | 唯一值比例 |
|------|------|--------|------------|
| lgb | 0.5017 | 0.2887 | 1.89% |
| mlp | 0.5017 | 0.2887 | 1.89% |
| stack | 0.5017 | 0.2887 | 1.89% |
| qlib_ensemble | 0.5017 | 0.2887 | 1.89% |
| final | 0.5017 | 0.2887 | 1.89% |

**注意**：所有模型的统计值完全相同，这是因为：
1. 预测值经过了 **Rank 转换**（截面排名转换为百分位）
2. Rank 转换后，所有模型的预测值分布都被标准化为 [0, 1] 的均匀分布

### 2.2 模型相关性分析

**相关系数矩阵**：

| 模型 | lgb | mlp | stack | qlib_ensemble | final |
|------|-----|-----|-------|---------------|-------|
| **lgb** | 1.0000 | 0.6247 | 0.9848 | 0.9106 | **0.9562** |
| **mlp** | 0.6247 | 1.0000 | 0.6122 | 0.8767 | **0.8056** |
| **stack** | 0.9848 | 0.6122 | 1.0000 | 0.8959 | **0.9504** |
| **qlib_ensemble** | 0.9106 | 0.8767 | 0.8959 | 1.0000 | **0.9882** |
| **final** | 0.9562 | 0.8056 | 0.9504 | 0.9882 | 1.0000 |

**关键发现**：
1. **final 与 qlib_ensemble 相关性最高（0.9882）**：说明最终预测主要受 qlib_ensemble 影响
2. **final 与 lgb 相关性较高（0.9562）**：LGB 是基础模型，贡献较大
3. **final 与 mlp 相关性较低（0.8056）**：MLP 的贡献相对较小
4. **mlp 与其他模型相关性较低（0.61-0.62）**：MLP 提供了不同的预测视角

### 2.3 权重推断（通过回归分析）

通过线性回归推断各模型在 final 中的权重：

| 模型 | 回归系数（近似权重） | 与 final 的相关性 |
|------|---------------------|-------------------|
| **lgb** | 0.71 | 0.9562 |
| **mlp** | 0.31 | 0.8056 |
| **qlib_ensemble** | 0.99 | 0.9882 |

**注意**：由于 final 是多个模型的加权平均，回归系数之和可能不等于 1。

## 三、MLP 模型贡献分析

### 3.1 MLP 的 IC 表现

| 指标 | MLP | LGB | 差异 |
|------|-----|-----|------|
| 平均IC | **0.0950** | 0.1585 | -0.0635（MLP 较低） |
| IC标准差 | 0.0726 | 0.1085 | -0.0359（MLP 更稳定） |
| IC-IR | **1.3097** | 1.4607 | -0.1510（MLP 较低） |
| 正IC比例 | 95.0% | 90.0% | +5%（MLP 更稳定） |

**结论**：
- **MLP 的预测能力较弱**：平均 IC 比 LGB 低 40%（0.095 vs 0.158）
- **MLP 的稳定性较好**：IC 标准差更小，正 IC 比例更高
- **MLP 的 IC-IR 较低**：说明虽然稳定，但预测能力不足

### 3.2 MLP 的权重贡献

根据分析：
- **推断权重**：约 0.31（31%）
- **与 final 的相关性**：0.8056（中等）
- **平均绝对差异**：0.1319（13.19%）

**评估**：
- MLP 权重中等（约 31%），有一定贡献
- 但 MLP 的 IC 较低，可能拖累整体表现
- MLP 提供了不同的预测视角（与其他模型相关性较低），可能有助于降低过拟合风险

### 3.3 MLP 的作用评估

**正面作用**：
1. ✅ **提供多样性**：MLP 与其他模型相关性较低（0.61-0.62），提供了不同的预测视角
2. ✅ **稳定性**：MLP 的 IC 波动较小，正 IC 比例高（95%）
3. ✅ **降低过拟合风险**：多个模型的集成可以降低单一模型的过拟合风险

**负面作用**：
1. ❌ **预测能力较弱**：MLP 的平均 IC 比 LGB 低 40%
2. ❌ **可能拖累整体表现**：如果 MLP 的权重过高，可能降低最终预测的 IC

## 四、建议与优化方向

### 4.1 当前状态评估

**总体评估**：
- ✅ **权重分配机制合理**：基于 IC-IR 动态加权，符合量化投资实践
- ⚠️ **MLP 贡献有限**：MLP 的 IC 较低，但权重仍占约 31%，可能不是最优配置
- ✅ **模型多样性良好**：MLP 与其他模型相关性较低，提供了多样性

### 4.2 优化建议

#### 建议 1：降低 MLP 权重

**原因**：
- MLP 的 IC-IR 最低（1.31），但推断权重却达到 31%
- 这可能是因为权重计算时考虑了所有模型，而 MLP 的 min_weight=0.05 约束可能不够严格

**方案**：
```yaml
# config/pipeline.yaml
ic_logging:
  window: 60
  half_life: 20
  min_weight: 0.02  # 降低最小权重，允许 MLP 权重更低
  max_weight: 0.7
```

#### 建议 2：优化 MLP 模型配置

**原因**：
- MLP 的 IC 较低（0.095），可能是模型配置不当

**方案**：
- 检查 `config/model_mlp.yaml` 中的配置
- 考虑增加隐藏层维度或调整学习率
- 考虑使用更复杂的网络结构

#### 建议 3：考虑移除 MLP

**原因**：
- 如果 MLP 的贡献持续较低，可以考虑移除 MLP，只使用 LGB + Stack

**方案**：
```yaml
# config/pipeline.yaml
ensemble:
  models:
    - name: "lgb"
      type: "lightgbm"
      config_key: "lightgbm_config"
    # 移除 MLP
    # - name: "mlp"
    #   type: "mlp"
    #   config_key: "mlp_config"
```

#### 建议 4：使用 Meta-Learner 替代动态加权

**原因**：
- Meta-Learner 可以学习如何最优组合各模型，而不是简单的加权平均

**方案**：
```yaml
# config/pipeline.yaml
ensemble:
  aggregator: "meta_learner_ridge"  # 使用 Meta-Learner
  aggregator_params:
    model_type: "ridge"
    alpha: 1.0
```

### 4.3 监控指标

建议持续监控以下指标：
1. **各模型的 IC 趋势**：如果 MLP 的 IC 持续下降，考虑降低权重或移除
2. **最终预测的 IC**：如果移除 MLP 后 IC 提升，说明 MLP 确实在拖累表现
3. **模型相关性**：如果 MLP 与其他模型相关性上升，说明 MLP 的多样性价值降低

## 五、总结

### 5.1 权重分配机制

- ✅ **机制合理**：基于 IC-IR 动态加权，符合量化投资实践
- ✅ **实现正确**：代码逻辑清晰，权重计算准确

### 5.2 MLP 的贡献

- ⚠️ **贡献有限**：MLP 的 IC 较低（0.095），但权重仍占约 31%
- ✅ **提供多样性**：MLP 与其他模型相关性较低，提供了不同的预测视角
- ⚠️ **可能拖累表现**：如果 MLP 的权重过高，可能降低最终预测的 IC

### 5.3 优化方向

1. **短期**：降低 MLP 的最小权重（min_weight），允许 MLP 权重更低
2. **中期**：优化 MLP 模型配置，提升 MLP 的 IC
3. **长期**：如果 MLP 贡献持续较低，考虑移除 MLP 或使用 Meta-Learner

### 5.4 关键指标

- **最终预测与 qlib_ensemble 相关性最高（0.9882）**：说明 qlib_ensemble 是主要贡献者
- **MLP 与 final 相关性中等（0.8056）**：说明 MLP 有一定贡献，但不是主要贡献者
- **MLP 的 IC-IR 最低（1.31）**：说明 MLP 的预测能力较弱，但稳定性较好


