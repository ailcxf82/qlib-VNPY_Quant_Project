model:
  # hidden_dims: [256, 128, 64]
  # dropout: 0.2
  # activation: "relu"
  # batch_size: 1024
  # lr: 0.001
  # weight_decay: 0.0
  # max_epochs: 50
  # patience: 5

  hidden_dims: [256, 128, 64]   # [修改] 稍微简化网络，强制压缩特征
  dropout: 0.3                 # 增加 Dropout，提高正则化（从0.3增加到0.4）
  activation: "relu"
  batch_size: 2048             # [修改] 增大 Batch Size 稳定梯度
  lr: 0.0005                   # [修改] 降低学习率
  weight_decay: 1e-4           # 增加权重衰减，提高正则化（从1e-4增加到5e-4）
  max_epochs: 100              # [修改] 增加轮数
  patience: 10                 # [修改] 增加早停耐心


